{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import random\n",
    "import shutil\n",
    "from collections import defaultdict\n",
    "# asdasdasd #copy the data before runnig this script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_id_list = {\n",
    "  0: 'ALLIGATOR(H)', 1: 'BLOCK', 2: 'LONGITUDINAL', 3: 'TRANSVERSE', 4: 'RUTTING',\n",
    "  5: 'RAVELING(H)', 6: 'CORRUGATION', 7: 'POTHOLE', 8: 'DEPRESSION', 9: 'EDGE CRACKING',\n",
    "  10: 'RAIL ROAD CROSSING', 11: 'BLEEDING', 12: 'JOINT REFLECTION', 13: 'PATCHING',\n",
    "  14: 'POLISHED AGGREGATE', 15: 'SHOVING', 16: 'SLIPPAGE', 17: 'BUMPS & SAGS', 18: 'SWELL',\n",
    "  19: 'WEATHERING', 20: 'CARRIAGEWAY', 21: 'ALLIGATOR(L)', 22: 'ALLIGATOR(M)', 23: 'RAVELING(M)'\n",
    "}\n",
    "\n",
    "# Create directories for train and validation sets\n",
    "train_img_dir = 'Data/training/Final Data/train/images'\n",
    "train_lbl_dir = 'Data/training/Final Data/train/labels'\n",
    "valid_img_dir = 'Data/training/Final Data/valid/images'\n",
    "valid_lbl_dir = 'Data/training/Final Data/valid/labels'\n",
    "\n",
    "os.makedirs(train_img_dir, exist_ok=True)\n",
    "os.makedirs(train_lbl_dir, exist_ok=True)\n",
    "os.makedirs(valid_img_dir, exist_ok=True)\n",
    "os.makedirs(valid_lbl_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'Data/training/Raw Data/'\n",
    "txt_list = glob.glob(os.path.join(data_dir, '**', '*.txt'), recursive=True)\n",
    "txt_list = [x for x in txt_list if 'classes.txt' not in x]\n",
    "\n",
    "# Step 1: Read and parse the data\n",
    "file_class_mapping = defaultdict(list)\n",
    "class_counter = defaultdict(int)\n",
    "\n",
    "for file in txt_list:\n",
    "    with open(file, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        file_classes = set()\n",
    "        for line in lines:\n",
    "            class_id = int(line.split(' ')[0])\n",
    "            class_name = class_id_list[class_id]\n",
    "            file_classes.add(class_name)\n",
    "        file_class_mapping[file] = list(file_classes)\n",
    "        for class_name in file_classes:\n",
    "            class_counter[class_name] += 1\n",
    "\n",
    "# Step 2: Calculate the number of files needed for each class\n",
    "train_ratio = 0.8\n",
    "train_files_per_class = {class_name: int(count * train_ratio) for class_name, count in class_counter.items()}\n",
    "\n",
    "# Step 3: Shuffle and split while ensuring class distribution\n",
    "train_files = set()\n",
    "val_files = set()\n",
    "class_train_counter = defaultdict(int)\n",
    "class_val_counter = defaultdict(int)\n",
    "\n",
    "random.seed(42)\n",
    "shuffled_files = list(file_class_mapping.keys())\n",
    "random.shuffle(shuffled_files)\n",
    "\n",
    "# First pass: Try to add to training while respecting the required distribution\n",
    "for file in shuffled_files:\n",
    "    if all(class_train_counter[class_name] < train_files_per_class[class_name] for class_name in file_class_mapping[file]):\n",
    "        train_files.add(file)\n",
    "        for class_name in file_class_mapping[file]:\n",
    "            class_train_counter[class_name] += 1\n",
    "    else:\n",
    "        val_files.add(file)\n",
    "        for class_name in file_class_mapping[file]:\n",
    "            class_val_counter[class_name] += 1\n",
    "\n",
    "# Second pass: Distribute remaining files to the validation set if not already added\n",
    "for file in shuffled_files:\n",
    "    if file not in train_files and file not in val_files:\n",
    "        val_files.add(file)\n",
    "        for class_name in file_class_mapping[file]:\n",
    "            class_val_counter[class_name] += 1\n",
    "\n",
    "\n",
    "\n",
    "# Function to move files to appropriate directories\n",
    "def copy_files(files, img_dir, lbl_dir):\n",
    "    for file in files:\n",
    "        # Corresponding image file path\n",
    "        img_file = file.replace('.txt', '.jpg')  # assuming image files have .jpg extension\n",
    "        \n",
    "        # Move the txt file only if the corresponding image file exists\n",
    "        if os.path.exists(img_file):\n",
    "            shutil.copy(file, os.path.join(lbl_dir, os.path.basename(file)))\n",
    "            shutil.copy(img_file, os.path.join(img_dir, os.path.basename(img_file)))\n",
    "        else:\n",
    "            print(f\"Missing image for label file: {file}\")\n",
    "\n",
    "# Move training and validation files\n",
    "copy_files(train_files, train_img_dir, train_lbl_dir)\n",
    "copy_files(val_files, valid_img_dir, valid_lbl_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter_dict_train={}\n",
    "counter_dict_val={}\n",
    "\n",
    "train_lbls = os.listdir(train_lbl_dir)\n",
    "train_lbls = [x for x in train_lbls if 'classes.txt'  not in x]\n",
    "\n",
    "valid_lbls = os.listdir(valid_lbl_dir)\n",
    "valid_lbls = [x for x in valid_lbls if 'classes.txt'  not in x]\n",
    "\n",
    "for file in train_lbls:\n",
    "    with open(train_lbl_dir+os.sep+file,'r') as f:\n",
    "        lines = f.readlines()            \n",
    "        for line in lines:\n",
    "            class_id= int(line.split(' ')[0])\n",
    "            class_name = class_id_list[class_id]\n",
    "            if class_name in counter_dict_train:\n",
    "                counter_dict_train[class_name] += 1\n",
    "            else:\n",
    "                counter_dict_train[class_name] = 1\n",
    "                \n",
    "\n",
    "for file in valid_lbls:\n",
    "    with open(valid_lbl_dir+os.sep+file,'r') as f:\n",
    "        lines = f.readlines()            \n",
    "        for line in lines:\n",
    "            class_id= int(line.split(' ')[0])\n",
    "            class_name = class_id_list[class_id]\n",
    "            if class_name in counter_dict_val:\n",
    "                counter_dict_val[class_name] += 1\n",
    "            else:\n",
    "                counter_dict_val[class_name] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crack Name\tTrain\tValid\t  After\t  Train\t  Valid\n",
      "................................\t ...............\n",
      "CARRIAGEWAY \t 9664 \t 2416 \t \t 9651 \t 2413\n",
      "RAVELING(M) \t 1436 \t 356 \t \t 1401 \t 351\n",
      "RAVELING(H) \t 9194 \t 2294 \t \t 8025 \t 2007\n",
      "WEATHERING \t 1649 \t 407 \t \t 1542 \t 386\n",
      "RUTTING \t 172 \t 44 \t \t 172 \t 44\n",
      "ALLIGATOR(H) \t 302 \t 74 \t \t 228 \t 60\n",
      "BLOCK \t 19 \t 5 \t \t 19 \t 5\n",
      "POTHOLE \t 25 \t 7 \t \t 25 \t 7\n",
      "POLISHED AGGREGATE \t 24 \t 8 \t \t 24 \t 8\n",
      "CORRUGATION \t 128 \t 32 \t \t 128 \t 32\n",
      "........................................................\n",
      "\n",
      "\t\tImages\tLabels\n",
      "Training:\t  9651 \t 9651\n",
      "Validation:\t  2413 \t 2413\n"
     ]
    }
   ],
   "source": [
    "# Output the counts for verification\n",
    "\n",
    "print('Crack Name\\tTrain\\tValid\\t  After\\t  Train\\t  Valid\\n................................\\t ...............')\n",
    "for key,value in counter_dict_train.items():\n",
    "    print(key,'\\t',value,'\\t',counter_dict_val[key],'\\t','\\t'   , class_train_counter[key],'\\t',class_val_counter[key])\n",
    "print('........................................................\\n')\n",
    "\n",
    "print('\\t\\tImages\\tLabels')\n",
    "print(\"Training:\\t \", len(os.listdir(train_img_dir)), \"\\t\", len(os.listdir(train_lbl_dir)))\n",
    "print(\"Validation:\\t \", len(os.listdir(valid_img_dir)), \"\\t\", len(os.listdir(valid_lbl_dir)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolov8test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
